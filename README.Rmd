---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# MixedUpParents-sims-and-analyses


## Notes on SEDNA

Something weird goes on with SEDNA whereby the slim_sim rule writes all its output
no problem, and then fails when returning control back to Snakemake.  It might
have something to do with the reticulate package and its conda environment.

At any rate, you can run it like this (which is assuming that we are running snakemake
on a node with 10 cores, 9 of which we will use for local jobs):
```sh
snakemake -np --use-envmodules --keep-incomplete --until slim_sim --profile hpcc-profiles/slurm/sedna
```
and once that is done, the outputs will still be there and you can continue by simply
removing the `.snakemake/incomplete` directory and then doing:
```sh
snakemake -np --use-envmodules --use-conda --local-cores 19 --profile hpcc-profiles/slurm/sedna
```

Total PITA.  Gonna have to figure out why it is failing, but we can use the above
until that time.

We might be able to use --cleanup-metadata 

Note, the --use-conda on the second line is to have bedtools for mup_logls.

You gotta define a MUP_CONDA variable, too. see the readme for MixedUpSlimSims for that.






## Notes on scenarios:

**Langford simulations**

Migration rates: symmetrical at 0, 2, 5, and 10%
Missing indiv rate: 0, 25, 50, 75%
Missing locus rate: 0, 0.15, 0.25, 0.5

5 reps of each.

Don't bother with Sequoia for the same cohort included runs, none of them
finished!

Calculate number of markers shared for each pair.


**Sequoia Runs with smaller sample sizes**

I am making a separate config for these.  I am going to do:

- sampling fract = 0.5
- missing genotype rate = 0.25 or 0.5
- all migration rates
- pop sizes of 120

I hope that will finish.  This is all specified in a separate config called
`config/config_120.yaml`.

**Other cases**

Fst = 0, hack things up so that we can tease out how much performace is due to SOS
model vs better-estimated allele freqs.


## Making a sim-spec.csv file

This is just some example code on how to make these
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
sim_specs <- expand_grid(
  sim_scenario = c("cyclone_WF", "cyclone_nonWF"),
  num_reps = 5,
  pop_size_1 = 1200,
  pop_size_2 = 1200,
  nesting(
    mig_rate_1 = c(0.0, 0.02, 0.05, 0.1),
    mig_rate_2 = c(0.0, 0.02, 0.05, 0.1),
  ),
  prop_sampled = c(1.0, 0.75, 0.5, 0.25),
  err_var = 0.01,
  err_diag = 0.004,
  nesting(
    miss_var = c(0, 0.15, 0.25, 0.5),
    miss_diag = c(0, 0.15, 0.25, 0.5),
  )
)
```

Only do certain Sequoia runs.  Based on previous runs the only ones that will finish
in a reasonable amount of time appear to be:

- exclude_same_cohort
- var only
- missing locus proportion of 0, 0.15

# Making the small (120 indivs) simulations

```{r}
library(tidyverse)
sim_specs <- expand_grid(
  sim_scenario = c("small_cyclone_WF", "small_cyclone_nonWF"),
  num_reps = 5,
  pop_size_1 = 120,
  pop_size_2 = 120,
  nesting(
    mig_rate_1 = c(0.0, 0.02, 0.05, 0.1),
    mig_rate_2 = c(0.0, 0.02, 0.05, 0.1),
  ),
  prop_sampled = c(0.5),
  err_var = 0.01,
  err_diag = 0.004,
  nesting(
    miss_var = c(0.25, 0.5),
    miss_diag = c(0.25, 0.5),
  )
)
```

Even at that, with full sampling of individuals we might have some really long ones. But at least that will give us only  2 * 5 * 4 * 4 * 2 = 320 runs of sequoia, and they should be shorter

I will modify the aggregation functions to have an option to do only those.

I did that, and I was able to run it with:
```sh
snakemake -np --use-envmodules --use-conda --local-cores 3  --configfile config/config_120.yaml  --profile hpcc-profiles/slurm/sedna
```
5 of the sequoia runs had not finished in 48 hours.  So I just removed them from the
targets.  Those files are in 
```
config/black-lists/sequoia-short-run-timeouts.txt
```



# Getting The RelateAdmix part going

## Some important points here:

1. RelateAdmix has to be somewhere on the PATH.  It is not deployed via conda.
2. One has to think about which marker sets get used for different parts of the analysis.
   Even if `marker_set` is `only_var` we still want to add the diagnostic SNPs for the
   admixture analysis.  This is done in `relate-admix.R`.  So, ADMIXTURE is run with all the
   markers, regardless of what `marker_set` is. 
3. Because we might have different marker sets for ADMIXTURE and RelateAdmix, we have to
   process the allele frequendies (.P) file out of ADMIXTURE to make sure it only has
   allele frequencies for the markers that RelateAdmix is using.
4. It appears that both RelateAdmix and ADMIXTURE just spit output into the current
   working directory, which is really, really lame, and makes for a lot of BS overhead
   moving files around.
   
## Some Verifications and Checking

I have things running on my laptop with previously simulated data and  I can
run it like this:
```sh
snakemake  --cores 8  -p results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_all_pairs.rds

# note that the outputs that generates includes:
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_all_pairs.rds
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_intermediate/plink.ped
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_intermediate/binary.bed
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_intermediate/plink.map
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_intermediate/admixture_plink.ped
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_intermediate/admixture_binary.bed
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_intermediate/admixture_plink.map
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_intermediate/relate_admix_locus_mask.txt
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_intermediate/inds_file.tsv
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_both_diag_and_var_intermediate/output.k
```
If I want to do different version of it I can run the reps from 0 to 3 and the marker_set can
be `only_var` or `both_diag_and_var`.

At this juncture I really need to verify that things are working the way that I think the
are.   I will do this by confirming that:

1. ADMIXTURE is giving Q estimates that make sense.
2. The estimated allele frequencies from ADMIXTURE also make sense.

Let us quickly do that.  I just ran the rule to get:
```
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_only_var_all_pairs.rds
```
And part of the input was:
```
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/tweaked2mup.rds
```
Let's see if we have what we need to verify things:
```{r}
library(tidyverse)

# the tweaked2mup result has the admixture fractions, at least 
t2m <- read_rds("results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/tweaked2mup.rds")

# get the inferred Q values
binQ <- read_table(
  "results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_only_var_intermediate/binary.2.Q",
  col_names = c("Q1", "Q2")
)

# and also get the order of the individuals from the pedfile
admixture_IDs <- read_tsv(
  "results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_only_var_intermediate/admixture_plink.ped",
  col_names = FALSE
) %>%
  mutate(X2 = str_replace(X2, "x", "")) %>%
  pull(X2)

binQ2 <- binQ %>%
  mutate(ID = as.integer(admixture_IDs))

# Now we can compare the Q's to the truth
trueQs <- t2m$sampled_pedQ %>%
  select(ped_id, anc_pop, admix_fract) %>%
  pivot_wider(names_from = anc_pop, values_from = admix_fract)

Q_compare <- trueQs %>%
  left_join(binQ2, by = join_by(ped_id == ID))

# looking at that, it is clear that anc_pop == 2 is what ADMIXTURE labelled as Q1
# so, here it goes:
ggplot(Q_compare, aes(x = `2`, y = Q1)) +
  geom_point() +
  xlab("True Admixture Fraction") +
  ylab("ADMIXTURE Estimated Fraction") +
  geom_abline(intercept = 0, slope = 1, colour = "red", linetype = "dashed")
```

OK.  It is clear that the individuals in there are all correct, but that ADMIXTURE
doesn't do a great job of estimating this stuff. I am guessing that is because we
have different amounts of markers that are diagnostic and variable from each of the
populations.  But I am satisfied that we have all the IDs of the individuals, correct,
etc.

So, now it would be good to check up on the estimated allele frequencies.  
```{r}
# get the inferred allele freqs that were given to RelateAdmix
binP <- read_table(
  "results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_only_var_intermediate/binary.2.P",
  col_names = c("P1", "P2")
)

# there are 628 of those. We know they will be in chromosome order.  And these
# are the variable ones only. I suspect they were from Cyclone or Langford.  Let's
# get both and check
cyc <- read_rds("config/var_freqs/cyclone-var-freqs.rds")
lang <- read_rds("config/var_freqs/langford-var-freqs.rds")

# OK. Cyclone has 628 markers, so lets add these on there and see what it looks like
P_compare <- bind_cols(
  cyc,
  binP
)

# This is sort of weird, because P1 looks like RBT, but the orientiation of the alleles
# is different, so we expect things to either fall on the y=x or the y=1-x line.
# Let's plot it:
ggplot(P_compare, aes(x = RBT, y = P1)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, colour = "red", linetype = "dashed") +
  geom_abline(intercept = 1, slope = -1, colour = "red", linetype = "dashed")
```

And we can do the same thing with WCT and P2:
```{r}
ggplot(P_compare, aes(x = WCT, y = P2)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, colour = "red", linetype = "dashed") +
  geom_abline(intercept = 1, slope = -1, colour = "red", linetype = "dashed")
```

OK! This is unambiguous: RelateAdmix is getting all the data just as it should be,
and it still really blows chunks at finding parents in the data. From what I have seen,
I am not expecting it to perform well.

Another interesting thing here is that seeing these results makes it pretty clear
that ADMIXTURE and RelateAdmix that assume a single Q-value for each individual
and that markers are effectively unlinked and independent within that are pretty
bad.  This excites me for the prospects of doing admixture like things on local
chunks in a chunkyG framework.  I think that is going to work very well, at least
in cases that are not dominated by isolation by distance.


## What metric should we use to rank pairs? 

I had originally thought I would use the coefficient of relatedness: $2k_1 + k_2$, but
this is untenable because so many pairs have k2=1, which is just weird, right---that
is what you expect from monozygous twins.  So RelateAdmix is not performing well.

But, I am going to do my due diligence to try to make it work as well as it can,
so let's look at the distribution of these things.  From the var_only data set
we were working with above, we have values for all of the pairs.
These results had been generated into:
```
results/scenario-nonWF_simple/ps1-1200-ps2-1200-mr1-0.06-mr2-0.02/rep-0/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.25-dmiss-0.25/relate_admix_only_var_all_pairs.rds
```
But I have copied them into:
```
stored-results/relate_admix_only_var_all_pairs.rds
```
And we can get it now, and count up how many pairs are in it:
```{r}
raov <- read_rds("stored-results/relate_admix_only_var_all_pairs.rds")
raov %>%
  filter(max_hit <= 2) %>%
  mutate(relat = str_c(dom_relat, "-", max_hit)) %>%
  count(relat)


```

OK.  That is a lot of unrelated pairs.  I want to make a plot with some
unrelated pairs on it, but I don't want any more than FC-2's because I want
the facets to all have the same x-limits.  So let us grab 11158  U's as well.
We will randomly sample those 11158 as necessary and then we will
plot the k values ordered descending on k1, and then on k2 to see how things
look.
```{r, fig.height=15, fig.width=9}
set.seed(5)
arranged_pairs <- raov %>%
  filter(max_hit <= 2) %>%
  mutate(relat = str_c(dom_relat, "-", max_hit)) %>%
  filter(dom_relat != "U") %>%
  bind_rows(
    .,
    raov %>% filter(dom_relat == "U") %>% mutate(relat = "U-0") %>% slice_sample(n = 11158)
  ) %>%
  arrange(relat, desc(k1), desc(k2)) %>%
  group_by(relat) %>%
  mutate(index = 1:n()) %>%
  ungroup()

ggplot(arranged_pairs, aes(x = index, y = k1)) +
  geom_line(colour = "blue") +
  geom_line(aes(y = k2), colour = "red") +
  facet_wrap(~ relat, ncol = 1)
```

Some explanation of this is in order.  The x-axis in the index of pairs that are sorted descending on their $k_1$
values (and secondarily on their $k_2$ values). So, each little position on the $x$-axis corresponds to a pair. The
blue line is the $k_1$ value of the pair.  The red line is the $k_2$ value of the pair, and, of course, the $k_0$
value is $1 - k_1 - k_2$.  We do see that the PO-1's (the parent offspring pairs) seem to have the largest fraction
of total pairs that have high $k_1$ values, but it is a tiny few of them.  All the related groups have more high-$k_1$
values than the unrelated pairs, but that is a tiny fraction of all the unrelated pairs---only about 0.25% of all of them.
Also, note that AN-2 are full
aunt-niece, Si-1 are half-siblings, Si-2 are full siblings, FC-2 are full first cousins, etc.  

The really crazy feature here is that RelateAdmix is inferring $k_2==1$ for a huge block of pairs.  That is crazy!
That should be reserved for monozygous twins.  My guess is that there is some numerical instability in the
optimization or something.  But that is not our problem.  

There are some full sibs that could be weeded out from the PO-1 pile be restricting to $k_2 < 0.15$, just by
eyeball, so that will be our full-sibling removal procedure, but I don't think it is going to make any 
difference because this is all so bad.  I expect it to perform worse than any other methods.

So, the criterion for calling a pair a PO will be to order them all in terms of $k_1$ and just work
down the taking them as they come.  But we will have a sibling removal strategy of tossing any pair
that has $k_2 > 0.15$.  I need to code that up in the compute_rocs function.  


## Running RelateAdmix on Alpine

I have all the old SLiM outputs from the original big run that I did on SEDNA, and now
I am going to just do the RelateAdmix parts on Alpine.  I should be able to do that without
simulating anything again.  I am going to take care of all of that in a new branch called
`relate-admix-on-alpine`.  The main changes will be:

1. An Alpine profile.
2. Running R in a conda environment that I already have set up
3. Modifying the inputs to gather_rocs so that it only inludes the RelateAdmix stuff.


I am testing the dry-run of that in the branch like this:
```sh
snakemake -np --rerun-triggers mtime --profile hpcc-profiles/slurm/alpine-smk9
```

Before I untarred the old results, this is what it would have to do:
```
Shell command: None
Job stats:
job             count
------------  -------
all                 1
compute_rocs     1280
gather_rocs         1
relate_admix     1280
slim_sim           40
tweak2mup         640
total            3242
```
But after I untarred the old results (that has all the simulation results, etc).

It still wants to regenerate some things because the file modification times for the
inputs to SLiM that I got from GitHub are today because I just cloned it.  So, I 
need to set those file mod times to before Jan 20, 2025.  Let' try:
```sh
touch -t 202501010000 config/slim_templates/*.slim config/var_freqs/cyclone-var-freqs.rds config/diag_markers/wct-rbt-yct-spp-diag-markers.rds
```
That seems to have done it.  Now, when I do, for one file:
```sh
snakemake -np --use-conda results/scenario-cyclone_nonWF/ps1-1200-ps2-1200-mr1-0.1-mr2-0.1/rep-4/ppn-0.5-verr-0.01-derr-0.004-vmiss-0.15-dmiss-0.15/relate_admix_both_diag_and_var_rocs.rds  --rerun-triggers mtime --profile hpcc-profiles/slurm/alpine-smk9
```
I get this:
```sh
Shell command: None
Job stats:
job             count
------------  -------
compute_rocs        1
relate_admix        1
total               2
```
So, now I just need to:

1. compile relateAdmix and link it to bin.
2. download admixture an link it to bin
3. installed plink 1.9 into a conda environment with `conda create -n plink bioconda::plink`,
   and then I symlinked plink in bin to the binary in that conda env
   
It all ran great, except about 120 of the jobs ran out of memory, so I upped those
to 8 cores and 25800 Mb.  
